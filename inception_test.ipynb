{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('myenv': conda)"
  },
  "interpreter": {
   "hash": "d82380b4268699ddf023b61d521e7fd1c6101c2e6b2a8dafc654ceb98eb585a7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from tensorflow.keras.applications import InceptionV3\r\n",
    "from PIL import Image\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from tensorflow import keras\r\n",
    "import numpy as np\r\n",
    "from os import listdir\r\n",
    "from os.path import isfile, join\r\n",
    "import math"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class SequenceGenerator(keras.utils.Sequence):\r\n",
    "    \"\"\"\r\n",
    "    A keras Sequence to be used as an image generator for the model.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, x, y, batchsize):\r\n",
    "        self.x, self.y, self.batchsize = x, y, batchsize\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return math.ceil(len(self.x) / self.batchsize)\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        x_names = self.x[idx * self.batchsize:(idx + 1) * self.batchsize]\r\n",
    "        y_names = np.asarray(self.y[idx * self.batchsize:(idx + 1) * self.batchsize])\r\n",
    "        \r\n",
    "        # open x image names, resize, normalise and make a numpy array\r\n",
    "        batch_x = np.array([np.asarray(Image.open(file_name).resize((299, 299))) for file_name in x_names]) / 255.0\r\n",
    "\r\n",
    "        return batch_x, y_names\r\n",
    "\r\n",
    "    def num_classes(self):\r\n",
    "        ret = []\r\n",
    "        for cat in self.y:\r\n",
    "            if cat not in ret:\r\n",
    "                ret.append(cat)\r\n",
    "        return len(ret)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def get_filenames_from_dir(directory, num_categories=1000):\r\n",
    "    x = []\r\n",
    "    y = []\r\n",
    "    category_count = 0\r\n",
    "    for category in listdir(directory):\r\n",
    "        for file in listdir(\"{0}/{1}\".format(directory, category)):\r\n",
    "            x.append(\"{0}/{1}/{2}\".format(directory, category, file))\r\n",
    "            y.append(category_count)\r\n",
    "        category_count += 1\r\n",
    "        if category_count == num_categories:\r\n",
    "            break\r\n",
    "\r\n",
    "    return x, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# makes arrays of the images and label names\r\n",
    "x_names, y_names = get_filenames_from_dir(\"database\", 50)\r\n",
    "\r\n",
    "# 15% of all the images are set aside as the test set\r\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x_names, y_names, test_size=0.15, random_state=42)\r\n",
    "\r\n",
    "# 17% of the non-test images are set aside as the validation set\r\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.17, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# make generators with batch size 16 for each set\r\n",
    "train_gen = SequenceGenerator(x_train, y_train, 16)\r\n",
    "val_gen = SequenceGenerator(x_val, y_val, 16)\r\n",
    "test_gen = SequenceGenerator(x_test, y_test, 16)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Inception model\r\n",
    "base_model = InceptionV3(weights=\"imagenet\")\r\n",
    "for layer in base_model.layers:\r\n",
    "    layer.trainable = False\r\n",
    "\r\n",
    "#predictions = keras.layers.GlobalAveragePooling2D()(base_model.output)\r\n",
    "predictions = keras.layers.Dense(1024, activation='relu')(base_model.output)\r\n",
    "predictions = keras.layers.Dense(2048, activation='relu')(predictions)\r\n",
    "predictions = keras.layers.Dense(1024, activation='relu')(predictions)\r\n",
    "predictions = keras.layers.Dense(train_gen.num_classes(), activation='softmax')(predictions)\r\n",
    "\r\n",
    "model = keras.Model(inputs=base_model.input, outputs=predictions)\r\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.fit(train_gen, validation_data=val_gen, epochs=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 605 steps, validate for 124 steps\n",
      "Epoch 1/10\n",
      "605/605 [==============================] - 157s 259ms/step - loss: 3.2847 - accuracy: 0.1020 - val_loss: 3.1645 - val_accuracy: 0.1079\n",
      "Epoch 2/10\n",
      "605/605 [==============================] - 138s 229ms/step - loss: 2.7054 - accuracy: 0.1770 - val_loss: 3.2695 - val_accuracy: 0.1326\n",
      "Epoch 3/10\n",
      "605/605 [==============================] - 138s 229ms/step - loss: 2.4609 - accuracy: 0.2336 - val_loss: 3.6183 - val_accuracy: 0.0888\n",
      "Epoch 4/10\n",
      "605/605 [==============================] - 138s 229ms/step - loss: 2.2861 - accuracy: 0.2745 - val_loss: 4.6289 - val_accuracy: 0.0726\n",
      "Epoch 5/10\n",
      "605/605 [==============================] - 138s 229ms/step - loss: 2.1434 - accuracy: 0.3126 - val_loss: 3.1553 - val_accuracy: 0.1508\n",
      "Epoch 6/10\n",
      "605/605 [==============================] - 138s 229ms/step - loss: 2.0335 - accuracy: 0.3464 - val_loss: 4.0833 - val_accuracy: 0.1114\n",
      "Epoch 7/10\n",
      "605/605 [==============================] - 138s 229ms/step - loss: 1.9049 - accuracy: 0.3767 - val_loss: 4.5691 - val_accuracy: 0.1034\n",
      "Epoch 8/10\n",
      "605/605 [==============================] - 138s 229ms/step - loss: 1.8462 - accuracy: 0.3937 - val_loss: 4.1759 - val_accuracy: 0.1276\n",
      "Epoch 9/10\n",
      "605/605 [==============================] - 138s 228ms/step - loss: 1.7563 - accuracy: 0.4180 - val_loss: 4.0762 - val_accuracy: 0.1326\n",
      "Epoch 10/10\n",
      "605/605 [==============================] - 138s 229ms/step - loss: 1.6995 - accuracy: 0.4358 - val_loss: 3.6694 - val_accuracy: 0.1427\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29bfb420408>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.evaluate(test_gen)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "129/129 [==============================] - 24s 188ms/step - loss: 3.7637 - accuracy: 0.1463\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3.7636766489162, 0.1462585]"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  }
 ]
}