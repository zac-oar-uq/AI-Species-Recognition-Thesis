{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from prepare_data import *\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5400 files belonging to 90 classes.\n",
      "Using 4590 files for training.\n",
      "Found 5400 files belonging to 90 classes.\n",
      "Using 810 files for validation.\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.ninety\n",
    "current_time = datetime.now().strftime(\"%d%m%Y-%H%M%S\")\n",
    "extractor_train, extractor_val = prep_data_single(dataset, 8)\n",
    "train_gen, val_gen = prep_data(dataset, extractor_train, extractor_val, 8, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 299, 299, 3)]     0         \n",
      "_________________________________________________________________\n",
      "random_flip (RandomFlip)     (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation (RandomRotat (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda) (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "inception_v3 (Functional)    (None, 1000)              23851784  \n",
      "=================================================================\n",
      "Total params: 23,851,784\n",
      "Trainable params: 23,817,352\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inception = InceptionV3(classifier_activation=None)\n",
    "inception.trainable = True\n",
    "\n",
    "inputs = keras.Input(shape=(299, 299, 3))\n",
    "flip_aug = experimental.preprocessing.RandomFlip()(inputs)\n",
    "rotate_aug = experimental.preprocessing.RandomRotation(0.2)(flip_aug)\n",
    "preprocessing = preprocess_input(rotate_aug)\n",
    "extractor = inception(preprocessing, training=False)\n",
    "inception_model = keras.Model(inputs=inputs, outputs=extractor)\n",
    "print(inception_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_logdir = \"logs/time_distributed/{0}_{1}/extractor\".format(str(dataset), current_time)\n",
    "extractor_tensorboard_callback = keras.callbacks.TensorBoard(log_dir=extractor_logdir)\n",
    "\n",
    "extractor_model_path = \"models/time_distributed/{0}_{1}/extractor/savefile.hdf5\".format(str(dataset), current_time)\n",
    "extractor_model_save_callback = keras.callbacks.ModelCheckpoint(filepath=extractor_model_path, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Functional)           (None, 1000)              23851784  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 291)               291291    \n",
      "=================================================================\n",
      "Total params: 24,143,075\n",
      "Trainable params: 24,108,643\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = keras.Sequential([inception_model, keras.layers.Dense(train_gen.num_classes(), activation='softmax')])\n",
    "feature_extractor.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(feature_extractor.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "6733/6733 [==============================] - 694s 100ms/step - loss: 2.2361 - accuracy: 0.4619 - val_loss: 1.1079 - val_accuracy: 0.6622\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66225, saving model to models/time_distributed/Dataset.carabid_25022022-105409/extractor\\savefile.hdf5\n",
      "Epoch 2/15\n",
      "6733/6733 [==============================] - 681s 101ms/step - loss: 0.8554 - accuracy: 0.7379 - val_loss: 0.8088 - val_accuracy: 0.7544\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66225 to 0.75442, saving model to models/time_distributed/Dataset.carabid_25022022-105409/extractor\\savefile.hdf5\n",
      "Epoch 3/15\n",
      "6733/6733 [==============================] - 681s 101ms/step - loss: 0.6161 - accuracy: 0.8060 - val_loss: 0.6207 - val_accuracy: 0.8128\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.75442 to 0.81282, saving model to models/time_distributed/Dataset.carabid_25022022-105409/extractor\\savefile.hdf5\n",
      "Epoch 4/15\n",
      "6733/6733 [==============================] - 680s 101ms/step - loss: 0.4833 - accuracy: 0.8470 - val_loss: 0.6100 - val_accuracy: 0.8136\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.81282 to 0.81355, saving model to models/time_distributed/Dataset.carabid_25022022-105409/extractor\\savefile.hdf5\n",
      "Epoch 5/15\n",
      "6733/6733 [==============================] - 679s 101ms/step - loss: 0.4060 - accuracy: 0.8696 - val_loss: 0.4894 - val_accuracy: 0.8521\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.81355 to 0.85206, saving model to models/time_distributed/Dataset.carabid_25022022-105409/extractor\\savefile.hdf5\n",
      "Epoch 6/15\n",
      "6733/6733 [==============================] - 679s 101ms/step - loss: 0.3421 - accuracy: 0.8882 - val_loss: 0.4587 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.85206 to 0.86595, saving model to models/time_distributed/Dataset.carabid_25022022-105409/extractor\\savefile.hdf5\n",
      "Epoch 7/15\n",
      "6733/6733 [==============================] - 680s 101ms/step - loss: 0.2956 - accuracy: 0.9035 - val_loss: 0.4805 - val_accuracy: 0.8617\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.86595\n",
      "Epoch 8/15\n",
      "6733/6733 [==============================] - 681s 101ms/step - loss: 0.2588 - accuracy: 0.9153 - val_loss: 0.4708 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.86595\n",
      "Epoch 9/15\n",
      "6733/6733 [==============================] - 680s 101ms/step - loss: 0.2295 - accuracy: 0.9241 - val_loss: 0.4226 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.86595 to 0.88089, saving model to models/time_distributed/Dataset.carabid_25022022-105409/extractor\\savefile.hdf5\n",
      "Epoch 10/15\n",
      "6733/6733 [==============================] - 681s 101ms/step - loss: 0.2021 - accuracy: 0.9343 - val_loss: 0.4288 - val_accuracy: 0.8788\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.88089\n",
      "Epoch 11/15\n",
      "6733/6733 [==============================] - 681s 101ms/step - loss: 0.1831 - accuracy: 0.9386 - val_loss: 0.4437 - val_accuracy: 0.8773\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.88089\n",
      "Epoch 12/15\n",
      "6733/6733 [==============================] - 680s 101ms/step - loss: 0.1637 - accuracy: 0.9456 - val_loss: 0.5253 - val_accuracy: 0.8580\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.88089\n",
      "Epoch 13/15\n",
      "6733/6733 [==============================] - 680s 101ms/step - loss: 0.1483 - accuracy: 0.9505 - val_loss: 0.3929 - val_accuracy: 0.8961\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.88089 to 0.89615, saving model to models/time_distributed/Dataset.carabid_25022022-105409/extractor\\savefile.hdf5\n",
      "Epoch 14/15\n",
      "6733/6733 [==============================] - 681s 101ms/step - loss: 0.1380 - accuracy: 0.9538 - val_loss: 0.4339 - val_accuracy: 0.8857\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.89615\n",
      "Epoch 15/15\n",
      "6733/6733 [==============================] - 681s 101ms/step - loss: 0.1249 - accuracy: 0.9580 - val_loss: 0.4576 - val_accuracy: 0.8869\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.89615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17979017c70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor.fit(extractor_train, validation_data=extractor_val, callbacks=[extractor_tensorboard_callback, extractor_model_save_callback], epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, None, 1000)        23851784  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 2000)              16008000  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              2001000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 90)                90090     \n",
      "=================================================================\n",
      "Total params: 41,950,874\n",
      "Trainable params: 18,099,090\n",
      "Non-trainable params: 23,851,784\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = keras.models.load_model(\"models/time_distributed/NINETY-EXTRACTOR/extractor/savefile.hdf5\")\n",
    "inception_model = feature_extractor.layers[0].layers[-1]\n",
    "inception_model.trainable = False\n",
    "\n",
    "classifier_model = keras.Sequential([\n",
    "    InputLayer(input_shape=(None, 299, 299, 3)),\n",
    "    TimeDistributed(inception_model),\n",
    "    Bidirectional(LSTM(1000)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dense(train_gen.num_classes(), activation='softmax')\n",
    "])\n",
    "\n",
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.1, decay_steps=1000, decay_rate=0.9)\n",
    "classifier_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(classifier_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/time_distributed/{0}_{1}/classifier\".format(str(dataset), current_time)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "model_path = \"models/time_distributed/{0}_{1}/classifier/savefile.hdf5\".format(str(dataset), current_time)\n",
    "model_save_callback = keras.callbacks.ModelCheckpoint(filepath=model_path, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffleCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, generator):\n",
    "        self._generator = generator\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self._generator.shuffle()\n",
    "    \n",
    "train_shuffle_callback = ShuffleCallback(train_gen)\n",
    "val_shuffle_callback = ShuffleCallback(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  6/139 [>.............................] - ETA: 1:46 - loss: 4.6029 - accuracy: 0.0417WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2526s vs `on_train_batch_end` time: 0.4553s). Check your callbacks.\n",
      "139/139 [==============================] - 71s 414ms/step - loss: 4.2230 - accuracy: 0.1070 - val_loss: 3.7876 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to models/time_distributed/Dataset.ninety_27022022-002434/classifier\\savefile.hdf5\n",
      "Epoch 2/20\n",
      "139/139 [==============================] - 51s 366ms/step - loss: 3.3858 - accuracy: 0.5665 - val_loss: 3.0544 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.50000 to 0.87500, saving model to models/time_distributed/Dataset.ninety_27022022-002434/classifier\\savefile.hdf5\n",
      "Epoch 3/20\n",
      "139/139 [==============================] - 49s 351ms/step - loss: 2.5763 - accuracy: 0.8885 - val_loss: 2.3292 - val_accuracy: 0.9524\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.87500 to 0.95238, saving model to models/time_distributed/Dataset.ninety_27022022-002434/classifier\\savefile.hdf5\n",
      "Epoch 4/20\n",
      "139/139 [==============================] - 47s 342ms/step - loss: 1.8536 - accuracy: 0.9757 - val_loss: 1.6736 - val_accuracy: 0.9583\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.95238 to 0.95833, saving model to models/time_distributed/Dataset.ninety_27022022-002434/classifier\\savefile.hdf5\n",
      "Epoch 5/20\n",
      "139/139 [==============================] - 48s 342ms/step - loss: 1.2331 - accuracy: 0.9910 - val_loss: 1.1850 - val_accuracy: 0.9702\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.95833 to 0.97024, saving model to models/time_distributed/Dataset.ninety_27022022-002434/classifier\\savefile.hdf5\n",
      "Epoch 6/20\n",
      "139/139 [==============================] - 47s 337ms/step - loss: 0.7971 - accuracy: 0.9973 - val_loss: 0.8298 - val_accuracy: 0.9702\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.97024\n",
      "Epoch 7/20\n",
      "139/139 [==============================] - 48s 345ms/step - loss: 0.5050 - accuracy: 0.9991 - val_loss: 0.5751 - val_accuracy: 0.9821\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.97024 to 0.98214, saving model to models/time_distributed/Dataset.ninety_27022022-002434/classifier\\savefile.hdf5\n",
      "Epoch 8/20\n",
      "139/139 [==============================] - 47s 339ms/step - loss: 0.3351 - accuracy: 0.9982 - val_loss: 0.4299 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.98214 to 0.98810, saving model to models/time_distributed/Dataset.ninety_27022022-002434/classifier\\savefile.hdf5\n",
      "Epoch 9/20\n",
      "139/139 [==============================] - 48s 346ms/step - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.98810\n",
      "Epoch 10/20\n",
      "139/139 [==============================] - 47s 338ms/step - loss: 0.1571 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.98810\n",
      "Epoch 11/20\n",
      "139/139 [==============================] - 47s 339ms/step - loss: 0.1203 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9821\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.98810\n",
      "Epoch 12/20\n",
      "139/139 [==============================] - 47s 341ms/step - loss: 0.0939 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.98810\n",
      "Epoch 13/20\n",
      "139/139 [==============================] - 48s 344ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.98810\n",
      "Epoch 14/20\n",
      "139/139 [==============================] - 47s 340ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.1659 - val_accuracy: 0.9821\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.98810\n",
      "Epoch 15/20\n",
      "139/139 [==============================] - 48s 341ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9821\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.98810\n",
      "Epoch 16/20\n",
      "139/139 [==============================] - 47s 340ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9940\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.98810 to 0.99405, saving model to models/time_distributed/Dataset.ninety_27022022-002434/classifier\\savefile.hdf5\n",
      "Epoch 17/20\n",
      "139/139 [==============================] - 48s 344ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9940\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.99405\n",
      "Epoch 18/20\n",
      "139/139 [==============================] - 48s 343ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9940\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.99405\n",
      "Epoch 19/20\n",
      "139/139 [==============================] - 47s 341ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.99405\n",
      "Epoch 20/20\n",
      "139/139 [==============================] - 47s 340ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.99405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x276e6b52fa0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "classifier_model.fit(train_gen, validation_data=val_gen, callbacks=[tensorboard_callback, model_save_callback, train_shuffle_callback, val_shuffle_callback], epochs=20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f584d1f2099a3b6b1aabed6fa6c4f9531bcc1f97f929a8d4f3fbf52265911e6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('myenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
