{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('myenv': conda)"
  },
  "interpreter": {
   "hash": "1f584d1f2099a3b6b1aabed6fa6c4f9531bcc1f97f929a8d4f3fbf52265911e6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "from tensorflow.keras.applications import InceptionV3\r\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\r\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from tensorflow import keras\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "from os import listdir\r\n",
    "from os.path import isfile\r\n",
    "import math\r\n",
    "\r\n",
    "from datetime import datetime\r\n",
    "%load_ext tensorboard"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "class SequenceGenerator(keras.utils.Sequence):\r\n",
    "    \"\"\"\r\n",
    "    A keras Sequence to be used as an image generator for the model.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, x, y, batchsize, num):\r\n",
    "        self.x, self.y, self.batchsize, self.num = x, y, batchsize, num\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return math.ceil(len(self.x) / self.batchsize)\r\n",
    "\r\n",
    "    def names_at_batch(self, idx):\r\n",
    "        x_names = self.x[idx * self.batchsize:(idx + 1) * self.batchsize]\r\n",
    "        y_names = np.asarray(self.y[idx * self.batchsize:(idx + 1) * self.batchsize])\r\n",
    "        return x_names, y_names\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        x_names = self.x[idx * self.batchsize:(idx + 1) * self.batchsize]\r\n",
    "        y_names = np.asarray(self.y[idx * self.batchsize:(idx + 1) * self.batchsize])\r\n",
    "\r\n",
    "        # open x image names, resize, normalise and make a numpy array\r\n",
    "        x = np.asarray([preprocess_input(img_to_array(load_img(file_name[self.num], target_size=(299, 299)))) for file_name in x_names])\r\n",
    "\r\n",
    "        return x, y_names\r\n",
    "\r\n",
    "    def num_classes(self):\r\n",
    "        ret = []\r\n",
    "        for cat in self.y:\r\n",
    "            if cat not in ret:\r\n",
    "                ret.append(cat)\r\n",
    "        return len(ret)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "source": [
    "class ValGenerator(SequenceGenerator):\r\n",
    "    def __init__(self, x, y, batchsize):\r\n",
    "        super().__init__(x, y, batchsize, 0)\r\n",
    "        x1 = np.asarray([file_name[0] for file_name in self.x])\r\n",
    "        x2 = np.asarray([file_name[1] for file_name in self.x])\r\n",
    "        x3 = np.asarray([file_name[2] for file_name in self.x])\r\n",
    "        self.x = np.concatenate((x1, x2, x3))\r\n",
    "\r\n",
    "        self.y = np.concatenate((self.y, self.y, self.y)).astype(int)\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        x_names = self.x[idx * self.batchsize:(idx + 1) * self.batchsize]\r\n",
    "        y_names = np.asarray(self.y[idx * self.batchsize:(idx + 1) * self.batchsize])\r\n",
    "\r\n",
    "        x = np.asarray([preprocess_input(img_to_array(load_img(file_name, target_size=(299, 299)))) for file_name in x_names])\r\n",
    "\r\n",
    "        return x, y_names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "source": [
    "def get_filenames_from_dir(directory):\r\n",
    "    x = []\r\n",
    "    y = []\r\n",
    "    category_count = 0\r\n",
    "    for category in listdir(directory):\r\n",
    "        triplet = []\r\n",
    "        if isfile(category):\r\n",
    "            continue\r\n",
    "        for file in listdir(\"{0}/{1}\".format(directory, category)):\r\n",
    "            if file[-3:] != \"jpg\":\r\n",
    "                continue\r\n",
    "            triplet.append((\"{0}/{1}/{2}\".format(directory, category, file), category_count))\r\n",
    "            if len(triplet) == 3:\r\n",
    "                x.append([img[0] for img in triplet])\r\n",
    "                y.append(triplet[0][1])\r\n",
    "                triplet = []\r\n",
    "        category_count += 1\r\n",
    "\r\n",
    "    return x, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "source": [
    "# makes arrays of the images and label names\r\n",
    "x_names, y_names = get_filenames_from_dir(\"database\")\r\n",
    "\r\n",
    "# 15% of all the images are set aside as the test set\r\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x_names, y_names, test_size=0.15, random_state=42)\r\n",
    "\r\n",
    "# 17% of the non-test images are set aside as the validation set\r\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.17, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "source": [
    "# make generators with batch size 32 for each set\r\n",
    "train_gen1 = SequenceGenerator(x_train, y_train, 4, 0)\r\n",
    "train_gen2 = SequenceGenerator(x_train, y_train, 4, 1)\r\n",
    "train_gen3 = SequenceGenerator(x_train, y_train, 4, 2)\r\n",
    "val_gen = ValGenerator(x_val, y_val, 4)\r\n",
    "test_gen = ValGenerator(x_test, y_test, 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "source": [
    "# Model 1\r\n",
    "base_model1 = InceptionV3(weights=\"imagenet\")\r\n",
    "for layer in base_model1.layers:\r\n",
    "    layer._name += \"_1\"\r\n",
    "    layer.trainable = True\r\n",
    "predictions1 = keras.layers.Dense(291, activation='softmax')(base_model1.layers[-2].output)\r\n",
    "model1 = keras.Model(inputs=base_model1.input, outputs=predictions1)\r\n",
    "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
    "\r\n",
    "# Model 2\r\n",
    "base_model2 = InceptionV3(weights=\"imagenet\")\r\n",
    "for layer in base_model2.layers:\r\n",
    "    layer._name += \"_2\"\r\n",
    "    layer.trainable = True\r\n",
    "predictions2 = keras.layers.Dense(291, activation='softmax')(base_model2.layers[-2].output)\r\n",
    "model2 = keras.Model(inputs=base_model2.input, outputs=predictions2)\r\n",
    "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
    "\r\n",
    "# Model 3\r\n",
    "base_model3 = InceptionV3(weights=\"imagenet\")\r\n",
    "for layer in base_model3.layers:\r\n",
    "    layer._name += \"_3\"\r\n",
    "    layer.trainable = True\r\n",
    "predictions3 = keras.layers.Dense(291, activation='softmax')(base_model3.layers[-2].output)\r\n",
    "model3 = keras.Model(inputs=base_model3.input, outputs=predictions3)\r\n",
    "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "source": [
    "logdir1 = \"logs/3model_individual_unshared/model1_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
    "tensorboard_callback1 = keras.callbacks.TensorBoard(log_dir=logdir1)\r\n",
    "\r\n",
    "logdir2 = \"logs/3model_individual_unshared/model2_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
    "tensorboard_callback2 = keras.callbacks.TensorBoard(log_dir=logdir2)\r\n",
    "\r\n",
    "logdir3 = \"logs/3model_individual_unshared/model3_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
    "tensorboard_callback3 = keras.callbacks.TensorBoard(log_dir=logdir3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "source": [
    "model1.fit(train_gen1, validation_data=val_gen, callbacks=[tensorboard_callback1], epochs=20)\r\n",
    "print(\"Model 1 completed\\n\\n\")\r\n",
    "model2.fit(train_gen2, validation_data=val_gen, callbacks=[tensorboard_callback2], epochs=20)\r\n",
    "print(\"Model 2 completed\\n\\n\")\r\n",
    "model3.fit(train_gen3, validation_data=val_gen, callbacks=[tensorboard_callback3], epochs=20)\r\n",
    "print(\"Model 3 completed\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "3709/3709 [==============================] - 331s 87ms/step - loss: 5.4850 - accuracy: 0.0147 - val_loss: 5.3287 - val_accuracy: 0.0179\n",
      "Epoch 2/20\n",
      "3709/3709 [==============================] - 312s 84ms/step - loss: 5.0547 - accuracy: 0.0280 - val_loss: 5.9792 - val_accuracy: 0.0321\n",
      "Epoch 3/20\n",
      "3709/3709 [==============================] - 309s 83ms/step - loss: 4.6365 - accuracy: 0.0473 - val_loss: 4.6945 - val_accuracy: 0.0342\n",
      "Epoch 4/20\n",
      "3709/3709 [==============================] - 309s 83ms/step - loss: 4.2164 - accuracy: 0.0760 - val_loss: 4.1810 - val_accuracy: 0.0850\n",
      "Epoch 5/20\n",
      "3709/3709 [==============================] - 309s 83ms/step - loss: 3.7337 - accuracy: 0.1325 - val_loss: 4.8716 - val_accuracy: 0.0646\n",
      "Epoch 6/20\n",
      "3709/3709 [==============================] - 310s 84ms/step - loss: 3.1952 - accuracy: 0.2095 - val_loss: 3.9616 - val_accuracy: 0.1419\n",
      "Epoch 7/20\n",
      "3709/3709 [==============================] - 309s 83ms/step - loss: 2.6943 - accuracy: 0.2932 - val_loss: 3.8390 - val_accuracy: 0.1909\n",
      "Epoch 8/20\n",
      "3709/3709 [==============================] - 309s 83ms/step - loss: 2.2502 - accuracy: 0.3795 - val_loss: 3.4481 - val_accuracy: 0.2501\n",
      "Epoch 9/20\n",
      "3709/3709 [==============================] - 310s 84ms/step - loss: 1.8658 - accuracy: 0.4663 - val_loss: 2.2303 - val_accuracy: 0.3825\n",
      "Epoch 10/20\n",
      "3709/3709 [==============================] - 312s 84ms/step - loss: 1.5605 - accuracy: 0.5396 - val_loss: 2.5390 - val_accuracy: 0.2917\n",
      "Epoch 11/20\n",
      "3709/3709 [==============================] - 315s 85ms/step - loss: 1.3028 - accuracy: 0.6064 - val_loss: 2.5600 - val_accuracy: 0.3413\n",
      "Epoch 12/20\n",
      "3709/3709 [==============================] - 308s 83ms/step - loss: 1.0840 - accuracy: 0.6702 - val_loss: 1.4882 - val_accuracy: 0.5552\n",
      "Epoch 13/20\n",
      "3709/3709 [==============================] - 309s 83ms/step - loss: 0.8953 - accuracy: 0.7180 - val_loss: 2.1607 - val_accuracy: 0.4271\n",
      "Epoch 14/20\n",
      "3709/3709 [==============================] - 309s 83ms/step - loss: 0.7304 - accuracy: 0.7704 - val_loss: 1.6797 - val_accuracy: 0.5176\n",
      "Epoch 15/20\n",
      "3709/3709 [==============================] - 308s 83ms/step - loss: 0.5909 - accuracy: 0.8124 - val_loss: 2.7901 - val_accuracy: 0.3713\n",
      "Epoch 16/20\n",
      "3709/3709 [==============================] - 308s 83ms/step - loss: 0.4695 - accuracy: 0.8511 - val_loss: 2.0217 - val_accuracy: 0.5118\n",
      "Epoch 17/20\n",
      "3709/3709 [==============================] - 305s 82ms/step - loss: 0.3842 - accuracy: 0.8749 - val_loss: 1.8759 - val_accuracy: 0.5255\n",
      "Epoch 18/20\n",
      "3709/3709 [==============================] - 302s 81ms/step - loss: 0.3230 - accuracy: 0.8977 - val_loss: 1.7684 - val_accuracy: 0.5515\n",
      "Epoch 19/20\n",
      "3709/3709 [==============================] - 300s 81ms/step - loss: 0.2658 - accuracy: 0.9171 - val_loss: 1.4897 - val_accuracy: 0.6202\n",
      "Epoch 20/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 0.2339 - accuracy: 0.9287 - val_loss: 2.6556 - val_accuracy: 0.4695\n",
      "Model 1 completed\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "3709/3709 [==============================] - 321s 85ms/step - loss: 5.4968 - accuracy: 0.0158 - val_loss: 7.2749 - val_accuracy: 0.0139\n",
      "Epoch 2/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 5.3486 - accuracy: 0.0175 - val_loss: 6.4848 - val_accuracy: 0.0095\n",
      "Epoch 3/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 4.9802 - accuracy: 0.0320 - val_loss: 8.6880 - val_accuracy: 0.0343\n",
      "Epoch 4/20\n",
      "3709/3709 [==============================] - 298s 80ms/step - loss: 4.6317 - accuracy: 0.0477 - val_loss: 4.6382 - val_accuracy: 0.0694\n",
      "Epoch 5/20\n",
      "3709/3709 [==============================] - 298s 80ms/step - loss: 4.2959 - accuracy: 0.0688 - val_loss: 3.9838 - val_accuracy: 0.1105\n",
      "Epoch 6/20\n",
      "3709/3709 [==============================] - 298s 80ms/step - loss: 3.8364 - accuracy: 0.1227 - val_loss: 3.7332 - val_accuracy: 0.1464\n",
      "Epoch 7/20\n",
      "3709/3709 [==============================] - 300s 81ms/step - loss: 3.2124 - accuracy: 0.2101 - val_loss: 3.1721 - val_accuracy: 0.2266\n",
      "Epoch 8/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 2.6608 - accuracy: 0.3045 - val_loss: 2.9464 - val_accuracy: 0.2432\n",
      "Epoch 9/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 2.1833 - accuracy: 0.3977 - val_loss: 2.4060 - val_accuracy: 0.3614\n",
      "Epoch 10/20\n",
      "3709/3709 [==============================] - 298s 80ms/step - loss: 1.7819 - accuracy: 0.4918 - val_loss: 2.2786 - val_accuracy: 0.4068\n",
      "Epoch 11/20\n",
      "3709/3709 [==============================] - 301s 81ms/step - loss: 1.4513 - accuracy: 0.5758 - val_loss: 1.5690 - val_accuracy: 0.5491\n",
      "Epoch 12/20\n",
      "3709/3709 [==============================] - 298s 80ms/step - loss: 1.1424 - accuracy: 0.6568 - val_loss: 2.2222 - val_accuracy: 0.4198\n",
      "Epoch 13/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 0.9004 - accuracy: 0.7258 - val_loss: 1.6820 - val_accuracy: 0.5413\n",
      "Epoch 14/20\n",
      "3709/3709 [==============================] - 298s 80ms/step - loss: 0.6972 - accuracy: 0.7884 - val_loss: 1.7936 - val_accuracy: 0.5285\n",
      "Epoch 15/20\n",
      "3709/3709 [==============================] - 299s 80ms/step - loss: 0.5085 - accuracy: 0.8463 - val_loss: 1.6580 - val_accuracy: 0.5672\n",
      "Epoch 16/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 0.3822 - accuracy: 0.8826 - val_loss: 1.8451 - val_accuracy: 0.5581\n",
      "Epoch 17/20\n",
      "3709/3709 [==============================] - 298s 80ms/step - loss: 0.2998 - accuracy: 0.9087 - val_loss: 2.4884 - val_accuracy: 0.4564\n",
      "Epoch 18/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 0.2485 - accuracy: 0.9279 - val_loss: 1.8630 - val_accuracy: 0.5831\n",
      "Epoch 19/20\n",
      "3709/3709 [==============================] - 298s 80ms/step - loss: 0.1906 - accuracy: 0.9455 - val_loss: 2.5567 - val_accuracy: 0.4732\n",
      "Epoch 20/20\n",
      "3709/3709 [==============================] - 298s 80ms/step - loss: 0.1812 - accuracy: 0.9484 - val_loss: 3.0147 - val_accuracy: 0.4850\n",
      "Model 2 completed\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "3709/3709 [==============================] - 324s 86ms/step - loss: 5.5316 - accuracy: 0.0131 - val_loss: 10.5051 - val_accuracy: 0.0186\n",
      "Epoch 2/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 5.4987 - accuracy: 0.0138 - val_loss: 9.5023 - val_accuracy: 0.0147\n",
      "Epoch 3/20\n",
      "3709/3709 [==============================] - 300s 81ms/step - loss: 5.4901 - accuracy: 0.0140 - val_loss: 7.8003 - val_accuracy: 0.0152\n",
      "Epoch 4/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 5.4787 - accuracy: 0.0147 - val_loss: 7.3033 - val_accuracy: 0.0138\n",
      "Epoch 5/20\n",
      "3709/3709 [==============================] - 302s 81ms/step - loss: 5.4741 - accuracy: 0.0146 - val_loss: 13.3718 - val_accuracy: 0.0136\n",
      "Epoch 6/20\n",
      "3709/3709 [==============================] - 301s 81ms/step - loss: 5.4738 - accuracy: 0.0133 - val_loss: 10.0131 - val_accuracy: 0.0132\n",
      "Epoch 7/20\n",
      "3709/3709 [==============================] - 298s 80ms/step - loss: 5.4520 - accuracy: 0.0142 - val_loss: 5.8455 - val_accuracy: 0.0194\n",
      "Epoch 8/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 5.2943 - accuracy: 0.0185 - val_loss: 5.1610 - val_accuracy: 0.0284\n",
      "Epoch 9/20\n",
      "3709/3709 [==============================] - 300s 81ms/step - loss: 5.1151 - accuracy: 0.0255 - val_loss: 18.8063 - val_accuracy: 0.0143\n",
      "Epoch 10/20\n",
      "3709/3709 [==============================] - 300s 81ms/step - loss: 4.9264 - accuracy: 0.0325 - val_loss: 4.9251 - val_accuracy: 0.0532\n",
      "Epoch 11/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 4.6463 - accuracy: 0.0513 - val_loss: 4.5239 - val_accuracy: 0.0687\n",
      "Epoch 12/20\n",
      "3709/3709 [==============================] - 300s 81ms/step - loss: 4.3409 - accuracy: 0.0697 - val_loss: 4.1752 - val_accuracy: 0.0874\n",
      "Epoch 13/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 4.0373 - accuracy: 0.0944 - val_loss: 4.2845 - val_accuracy: 0.0523\n",
      "Epoch 14/20\n",
      "3709/3709 [==============================] - 298s 80ms/step - loss: 3.6996 - accuracy: 0.1335 - val_loss: 3.7284 - val_accuracy: 0.1730\n",
      "Epoch 15/20\n",
      "3709/3709 [==============================] - 299s 81ms/step - loss: 3.3542 - accuracy: 0.1808 - val_loss: 3.7931 - val_accuracy: 0.2106\n",
      "Epoch 16/20\n",
      "3709/3709 [==============================] - 298s 80ms/step - loss: 3.0683 - accuracy: 0.2260 - val_loss: 16.1735 - val_accuracy: 0.1261\n",
      "Epoch 17/20\n",
      "3709/3709 [==============================] - 303s 82ms/step - loss: 3.0391 - accuracy: 0.2364 - val_loss: 5.0333 - val_accuracy: 0.2747\n",
      "Epoch 18/20\n",
      "3709/3709 [==============================] - 298s 80ms/step - loss: 2.5663 - accuracy: 0.3152 - val_loss: 3.1081 - val_accuracy: 0.3372\n",
      "Epoch 19/20\n",
      "3709/3709 [==============================] - 297s 80ms/step - loss: 2.2210 - accuracy: 0.3907 - val_loss: 2.6804 - val_accuracy: 0.3828\n",
      "Epoch 20/20\n",
      "3709/3709 [==============================] - 297s 80ms/step - loss: 1.9655 - accuracy: 0.4447 - val_loss: 2.3191 - val_accuracy: 0.3827\n",
      "Model 3 completed\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "source": [
    "model1.evaluate(test_gen)\r\n",
    "model2.evaluate(test_gen)\r\n",
    "model3.evaluate(test_gen)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2366/2366 [==============================] - 63s 27ms/step - loss: 2.6007 - accuracy: 0.4934\n",
      "2366/2366 [==============================] - 61s 26ms/step - loss: 2.9746 - accuracy: 0.4864\n",
      "2366/2366 [==============================] - 61s 26ms/step - loss: 2.3032 - accuracy: 0.3908\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[2.3031606674194336, 0.3908264636993408]"
      ]
     },
     "metadata": {},
     "execution_count": 188
    }
   ],
   "metadata": {}
  }
 ]
}