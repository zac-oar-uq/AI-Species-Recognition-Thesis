{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from prepare_data import *\n",
    "import albumentations as A\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63364 files belonging to 291 classes.\n",
      "Using 53860 files for training.\n",
      "Found 63364 files belonging to 291 classes.\n",
      "Using 9504 files for validation.\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.carabid\n",
    "dataset_name = str(dataset).split(\".\")[1]\n",
    "raw_train, raw_val = prep_data_single(dataset, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing standard dataset on standard model:\n",
      "1188/1188 [==============================] - 47s 30ms/step - loss: 0.3929 - accuracy: 0.8961\n",
      "Testing gray dataset on standard model:\n",
      "1188/1188 [==============================] - 51s 42ms/step - loss: 5.9423 - accuracy: 0.1652\n",
      "Testing blur dataset on standard model:\n",
      "1188/1188 [==============================] - 58s 49ms/step - loss: 6.0532 - accuracy: 0.3383\n",
      "Testing standard dataset on gray model:\n",
      "1188/1188 [==============================] - 42s 34ms/step - loss: 0.6064 - accuracy: 0.8343\n",
      "Testing gray dataset on gray model:\n",
      "1188/1188 [==============================] - 52s 43ms/step - loss: 0.6122 - accuracy: 0.8333\n",
      "Testing blur dataset on gray model:\n",
      "1188/1188 [==============================] - 58s 49ms/step - loss: 6.0923 - accuracy: 0.2715\n",
      "Testing standard dataset on blur model:\n",
      "1188/1188 [==============================] - 42s 34ms/step - loss: 0.4148 - accuracy: 0.8859\n",
      "Testing gray dataset on blur model:\n",
      "1188/1188 [==============================] - 51s 42ms/step - loss: 12.6130 - accuracy: 0.0133\n",
      "Testing blur dataset on blur model:\n",
      "1188/1188 [==============================] - 57s 48ms/step - loss: 0.4184 - accuracy: 0.8848\n",
      "{('standard', 'standard'): [0.39286190271377563, 0.8961489796638489], ('standard', 'gray'): [5.942285537719727, 0.1651936024427414], ('standard', 'blur'): [6.053205490112305, 0.3382786214351654], ('gray', 'standard'): [0.6064485907554626, 0.8342803120613098], ('gray', 'gray'): [0.6121507883071899, 0.8333333134651184], ('gray', 'blur'): [6.092301845550537, 0.27146464586257935], ('blur', 'standard'): [0.4148377478122711, 0.8859427571296692], ('blur', 'gray'): [12.61299991607666, 0.013257576152682304], ('blur', 'blur'): [0.41838258504867554, 0.8847853541374207]}\n"
     ]
    }
   ],
   "source": [
    "standard_model_path = f\"models/{dataset_name}/{dataset_name.upper()}-EXTRACTOR/extractor/savefile.hdf5\"\n",
    "standard_model = keras.models.load_model(standard_model_path)\n",
    "\n",
    "gray_model_path = f\"models/{dataset_name}/{dataset_name.upper()}-GRAY-EXTRACTOR/extractor/savefile.hdf5\"\n",
    "gray_model = keras.models.load_model(gray_model_path)\n",
    "\n",
    "blur_model_path = f\"models/{dataset_name}/{dataset_name.upper()}-BLUR-EXTRACTOR/extractor/savefile.hdf5\"\n",
    "blur_model = keras.models.load_model(blur_model_path)\n",
    "\n",
    "gray_aug = A.Compose([A.ToGray(p=1.0)])\n",
    "blur_aug = A.Compose([A.Blur(p=1.0)])\n",
    "\n",
    "def apply_aug_gray(images):\n",
    "    aug_imgs = []\n",
    "    for img in images:\n",
    "        aug_imgs.append(gray_aug(image=img)[\"image\"])\n",
    "    return np.array(aug_imgs)\n",
    "\n",
    "def apply_aug_blur(images):\n",
    "    aug_imgs = []\n",
    "    for img in images:\n",
    "        aug_imgs.append(blur_aug(image=img)[\"image\"])\n",
    "    return np.array(aug_imgs)\n",
    "\n",
    "def process_data_gray(images, labels):\n",
    "    aug_imgs = tf.numpy_function(apply_aug_gray, [images], tf.float32)\n",
    "    return aug_imgs, labels\n",
    "\n",
    "def process_data_blur(images, labels):\n",
    "    aug_imgs = tf.numpy_function(apply_aug_blur, [images], tf.float32)\n",
    "    return aug_imgs, labels\n",
    "\n",
    "standard_val = raw_val\n",
    "gray_val = raw_val.map(process_data_gray)\n",
    "blur_val = raw_val.map(process_data_blur)\n",
    "\n",
    "models = {\"standard\": standard_model, \"gray\": gray_model, \"blur\": blur_model}\n",
    "datasets = {\"standard\": standard_val, \"gray\": gray_val, \"blur\": blur_val}\n",
    "results = {}\n",
    "\n",
    "for m_name, m in models.items():\n",
    "    for d_name, d in datasets.items():\n",
    "        print(f\"Testing {d_name} dataset on {m_name} model:\")\n",
    "        results[(m_name, d_name)] = m.evaluate(d)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1f584d1f2099a3b6b1aabed6fa6c4f9531bcc1f97f929a8d4f3fbf52265911e6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('myenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
