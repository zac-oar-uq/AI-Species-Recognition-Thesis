{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('myenv': conda)"
  },
  "interpreter": {
   "hash": "1f584d1f2099a3b6b1aabed6fa6c4f9531bcc1f97f929a8d4f3fbf52265911e6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from tensorflow.keras.applications import InceptionV3\r\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\r\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from tensorflow import keras\r\n",
    "import numpy as np\r\n",
    "from os import listdir\r\n",
    "from os.path import isfile\r\n",
    "import math\r\n",
    "\r\n",
    "from datetime import datetime\r\n",
    "%load_ext tensorboard"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "class SequenceGenerator(keras.utils.Sequence):\r\n",
    "    \"\"\"\r\n",
    "    A keras Sequence to be used as an image generator for the model.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, x, y, batchsize):\r\n",
    "        self.x, self.y, self.batchsize = x, y, batchsize\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return math.ceil(len(self.x) / self.batchsize)\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        x_names = self.x[idx * self.batchsize:(idx + 1) * self.batchsize]\r\n",
    "        y_names = np.asarray(self.y[idx * self.batchsize:(idx + 1) * self.batchsize])\r\n",
    "        \r\n",
    "        # open x image names, resize, normalise and make a numpy array\r\n",
    "        batch_x = np.asarray([preprocess_input(img_to_array(load_img(file_name, target_size=(299, 299)))) for file_name in x_names])\r\n",
    "\r\n",
    "        return batch_x, y_names\r\n",
    "\r\n",
    "    def num_classes(self):\r\n",
    "        ret = []\r\n",
    "        for cat in self.y:\r\n",
    "            if cat not in ret:\r\n",
    "                ret.append(cat)\r\n",
    "        return len(ret)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def get_filenames_from_dir(directory, num_categories=1000):\r\n",
    "    x = []\r\n",
    "    y = []\r\n",
    "    category_count = 0\r\n",
    "    for category in listdir(directory):\r\n",
    "        if isfile(category):\r\n",
    "            continue\r\n",
    "        for file in listdir(\"{0}/{1}\".format(directory, category)):\r\n",
    "            if file[-3:] != \"jpg\":\r\n",
    "                continue\r\n",
    "            x.append(\"{0}/{1}/{2}\".format(directory, category, file))\r\n",
    "            y.append(category_count)\r\n",
    "        category_count += 1\r\n",
    "        if category_count == num_categories:\r\n",
    "            break\r\n",
    "\r\n",
    "    return x, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# makes arrays of the images and label names\r\n",
    "x_names, y_names = get_filenames_from_dir(\"database\")\r\n",
    "\r\n",
    "# 15% of all the images are set aside as the test set\r\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x_names, y_names, test_size=0.15, random_state=42)\r\n",
    "\r\n",
    "# 17% of the non-test images are set aside as the validation set\r\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.17, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# make generators with batch size 4 for each set\r\n",
    "train_gen = SequenceGenerator(x_train, y_train, 4)\r\n",
    "val_gen = SequenceGenerator(x_val, y_val, 4)\r\n",
    "test_gen = SequenceGenerator(x_test, y_test, 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Inception model\r\n",
    "base_model = InceptionV3(weights=\"imagenet\")\r\n",
    "for layer in base_model.layers:\r\n",
    "    layer.trainable = True\r\n",
    "\r\n",
    "predictions = keras.layers.Dense(train_gen.num_classes(), activation='softmax')(base_model.layers[-2].output)\r\n",
    "\r\n",
    "model = keras.Model(inputs=base_model.input, outputs=predictions)\r\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "logdir = \"logs/inception_single_model\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model.fit(train_gen, validation_data=val_gen, callbacks=[tensorboard_callback], epochs=20)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "11176/11176 [==============================] - 855s 75ms/step - loss: 5.1841 - accuracy: 0.0241 - val_loss: 4.7419 - val_accuracy: 0.0482\n",
      "Epoch 2/20\n",
      "11176/11176 [==============================] - 848s 76ms/step - loss: 4.0778 - accuracy: 0.0936 - val_loss: 3.3002 - val_accuracy: 0.1720\n",
      "Epoch 3/20\n",
      "11176/11176 [==============================] - 834s 75ms/step - loss: 2.5287 - accuracy: 0.3362 - val_loss: 1.9761 - val_accuracy: 0.4290\n",
      "Epoch 4/20\n",
      "11176/11176 [==============================] - 842s 75ms/step - loss: 1.5154 - accuracy: 0.5579 - val_loss: 1.4569 - val_accuracy: 0.5751\n",
      "Epoch 5/20\n",
      "11176/11176 [==============================] - 830s 74ms/step - loss: 1.0611 - accuracy: 0.6808 - val_loss: 1.3282 - val_accuracy: 0.6228\n",
      "Epoch 6/20\n",
      "11176/11176 [==============================] - 849s 76ms/step - loss: 0.7950 - accuracy: 0.7542 - val_loss: 0.8862 - val_accuracy: 0.7335\n",
      "Epoch 7/20\n",
      "11176/11176 [==============================] - 829s 74ms/step - loss: 0.6111 - accuracy: 0.8091 - val_loss: 0.8113 - val_accuracy: 0.7619\n",
      "Epoch 8/20\n",
      "11176/11176 [==============================] - 842s 75ms/step - loss: 0.4784 - accuracy: 0.8474 - val_loss: 0.7762 - val_accuracy: 0.7791\n",
      "Epoch 9/20\n",
      "11176/11176 [==============================] - 832s 74ms/step - loss: 0.3760 - accuracy: 0.8778 - val_loss: 1.3931 - val_accuracy: 0.7169\n",
      "Epoch 10/20\n",
      "11176/11176 [==============================] - 851s 76ms/step - loss: 0.2933 - accuracy: 0.9027 - val_loss: 1.0296 - val_accuracy: 0.7416\n",
      "Epoch 11/20\n",
      "11176/11176 [==============================] - 833s 75ms/step - loss: 0.2326 - accuracy: 0.9235 - val_loss: 0.8008 - val_accuracy: 0.8003\n",
      "Epoch 12/20\n",
      "11176/11176 [==============================] - 833s 75ms/step - loss: 0.1883 - accuracy: 0.9382 - val_loss: 0.7135 - val_accuracy: 0.8216\n",
      "Epoch 13/20\n",
      "11176/11176 [==============================] - 831s 74ms/step - loss: 0.1595 - accuracy: 0.9481 - val_loss: 0.9329 - val_accuracy: 0.7924\n",
      "Epoch 14/20\n",
      "11176/11176 [==============================] - 829s 74ms/step - loss: 0.1325 - accuracy: 0.9582 - val_loss: 0.9329 - val_accuracy: 0.8012\n",
      "Epoch 15/20\n",
      "11176/11176 [==============================] - 813s 73ms/step - loss: 0.1173 - accuracy: 0.9627 - val_loss: 0.8399 - val_accuracy: 0.8176\n",
      "Epoch 16/20\n",
      "11176/11176 [==============================] - 807s 72ms/step - loss: 0.1016 - accuracy: 0.9671 - val_loss: 0.8014 - val_accuracy: 0.8128\n",
      "Epoch 17/20\n",
      "11176/11176 [==============================] - 806s 72ms/step - loss: 0.0900 - accuracy: 0.9717 - val_loss: 0.8838 - val_accuracy: 0.8198\n",
      "Epoch 18/20\n",
      "11176/11176 [==============================] - 812s 73ms/step - loss: 0.0862 - accuracy: 0.9719 - val_loss: 1.0088 - val_accuracy: 0.7976\n",
      "Epoch 19/20\n",
      "11176/11176 [==============================] - 804s 72ms/step - loss: 0.0749 - accuracy: 0.9756 - val_loss: 0.9114 - val_accuracy: 0.8247\n",
      "Epoch 20/20\n",
      "11176/11176 [==============================] - 820s 73ms/step - loss: 0.0714 - accuracy: 0.9776 - val_loss: 0.9589 - val_accuracy: 0.8102\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ff148bf40>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model.evaluate(test_gen)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2377/2377 [==============================] - 61s 26ms/step - loss: 0.9384 - accuracy: 0.8113\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.9384143948554993, 0.8112572431564331]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  }
 ]
}