{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from prepare_data import *\n",
    "import albumentations as A\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63364 files belonging to 291 classes.\n",
      "Using 53860 files for training.\n",
      "Found 63364 files belonging to 291 classes.\n",
      "Using 9504 files for validation.\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.carabid\n",
    "dataset_name = str(dataset).split(\".\")[1]\n",
    "raw_train, raw_val = prep_dataset(dataset, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests the classification accuracy of extractors trained with standard (un-augmented), blurred and greyed images on each of the three image types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing standard dataset on standard model:\n",
      "1188/1188 [==============================] - 40s 29ms/step - loss: 0.3929 - accuracy: 0.8961\n",
      "Testing gray dataset on standard model:\n",
      "1188/1188 [==============================] - 42s 35ms/step - loss: 5.9422 - accuracy: 0.1652\n",
      "Testing blur dataset on standard model:\n",
      "1188/1188 [==============================] - 46s 39ms/step - loss: 6.0038 - accuracy: 0.3431\n",
      "Testing standard dataset on gray model:\n",
      "1188/1188 [==============================] - 36s 30ms/step - loss: 0.6064 - accuracy: 0.8342\n",
      "Testing gray dataset on gray model:\n",
      "1188/1188 [==============================] - 42s 35ms/step - loss: 0.6121 - accuracy: 0.8333\n",
      "Testing blur dataset on gray model:\n",
      "1188/1188 [==============================] - 46s 39ms/step - loss: 6.1340 - accuracy: 0.2635\n",
      "Testing standard dataset on blur model:\n",
      "1188/1188 [==============================] - 36s 29ms/step - loss: 0.4149 - accuracy: 0.8858\n",
      "Testing gray dataset on blur model:\n",
      "1188/1188 [==============================] - 42s 34ms/step - loss: 12.6120 - accuracy: 0.0133\n",
      "Testing blur dataset on blur model:\n",
      "1188/1188 [==============================] - 45s 38ms/step - loss: 0.4147 - accuracy: 0.8890\n",
      "{('standard', 'standard'): [0.39286965131759644, 0.8961489796638489], ('standard', 'gray'): [5.942202568054199, 0.1651936024427414], ('standard', 'blur'): [6.003777027130127, 0.34311869740486145], ('gray', 'standard'): [0.6064425110816956, 0.8341751098632812], ('gray', 'gray'): [0.6121371984481812, 0.8333333134651184], ('gray', 'blur'): [6.134037494659424, 0.26346802711486816], ('blur', 'standard'): [0.41485661268234253, 0.8858375549316406], ('blur', 'gray'): [12.611956596374512, 0.013257576152682304], ('blur', 'blur'): [0.41465064883232117, 0.8889940977096558]}\n"
     ]
    }
   ],
   "source": [
    "standard_model_path = f\"../model-saves/extractors/{dataset_name}/{dataset_name.upper()}-EXTRACTOR/extractor/savefile.hdf5\"\n",
    "standard_model = keras.models.load_model(standard_model_path)\n",
    "\n",
    "gray_model_path = f\"../model-saves/extractors/{dataset_name}/{dataset_name.upper()}-GRAY-EXTRACTOR/extractor/savefile.hdf5\"\n",
    "gray_model = keras.models.load_model(gray_model_path)\n",
    "\n",
    "blur_model_path = f\"../model-saves/extractors/{dataset_name}/{dataset_name.upper()}-BLUR-EXTRACTOR/extractor/savefile.hdf5\"\n",
    "blur_model = keras.models.load_model(blur_model_path)\n",
    "\n",
    "gray_aug = A.Compose([A.ToGray(p=1.0)])\n",
    "blur_aug = A.Compose([A.Blur(p=1.0)])\n",
    "\n",
    "def apply_aug_gray(images):\n",
    "    aug_imgs = []\n",
    "    for img in images:\n",
    "        aug_imgs.append(gray_aug(image=img)[\"image\"])\n",
    "    return np.array(aug_imgs)\n",
    "\n",
    "def apply_aug_blur(images):\n",
    "    aug_imgs = []\n",
    "    for img in images:\n",
    "        aug_imgs.append(blur_aug(image=img)[\"image\"])\n",
    "    return np.array(aug_imgs)\n",
    "\n",
    "def process_data_gray(images, labels):\n",
    "    aug_imgs = tf.numpy_function(apply_aug_gray, [images], tf.float32)\n",
    "    return aug_imgs, labels\n",
    "\n",
    "def process_data_blur(images, labels):\n",
    "    aug_imgs = tf.numpy_function(apply_aug_blur, [images], tf.float32)\n",
    "    return aug_imgs, labels\n",
    "\n",
    "standard_val = raw_val\n",
    "gray_val = raw_val.map(process_data_gray)\n",
    "blur_val = raw_val.map(process_data_blur)\n",
    "\n",
    "models = {\"standard\": standard_model, \"gray\": gray_model, \"blur\": blur_model}\n",
    "datasets = {\"standard\": standard_val, \"gray\": gray_val, \"blur\": blur_val}\n",
    "results = {}\n",
    "\n",
    "for m_name, m in models.items():\n",
    "    for d_name, d in datasets.items():\n",
    "        print(f\"Testing {d_name} dataset on {m_name} model:\")\n",
    "        results[(m_name, d_name)] = m.evaluate(d)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1ea28194a809bd3a64ba3a87b6ac05da64ff1233be85177613440de0ba72c6c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
