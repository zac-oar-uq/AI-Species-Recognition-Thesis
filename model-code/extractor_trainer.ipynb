{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from prepare_data import *\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "import albumentations as A\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.ninety\n",
    "dataset_name = str(dataset).split(\".\")[1]\n",
    "current_time = datetime.now().strftime(\"%d%m%Y-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional augments to train an augmented extractor\n",
    "augment = A.Compose([A.ToGray(p=1.0)])\n",
    "\n",
    "def apply_aug(images):\n",
    "    aug_imgs = []\n",
    "    for img in images:\n",
    "        aug_imgs.append(augment(image=img)[\"image\"])\n",
    "    return np.array(aug_imgs)\n",
    "\n",
    "def process_data(images, labels):\n",
    "    aug_imgs = tf.numpy_function(apply_aug, [images], tf.float32)\n",
    "    return aug_imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train, raw_val = prep_dataset(dataset, 8)\n",
    "extractor_train = raw_train.map(process_data)\n",
    "extractor_val = raw_val.map(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an inception model with ImageNet weights for re-training\n",
    "inception = InceptionV3(classifier_activation=None)\n",
    "inception.trainable = True\n",
    "\n",
    "# add preprocessing and augmentation to the model to improve training\n",
    "inputs = keras.Input(shape=(299, 299, 3))\n",
    "flip_aug = keras.experimental.preprocessing.RandomFlip()(inputs)\n",
    "rotate_aug = keras.experimental.preprocessing.RandomRotation(0.5)(flip_aug)\n",
    "preprocessing = preprocess_input(rotate_aug)\n",
    "extractor = inception(preprocessing, training=False)\n",
    "inception_model = keras.Model(inputs=inputs, outputs=extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks to save the logs and model each epoch\n",
    "extractor_logdir = \"../logs/unfiltered/extractor_{0}_{1}/extractor\".format(str(dataset), current_time)\n",
    "extractor_tensorboard_callback = keras.callbacks.TensorBoard(log_dir=extractor_logdir)\n",
    "\n",
    "extractor_model_path = \"../model-saves/unfiltered/extractor_{0}_{1}/extractor/savefile.hdf5\".format(str(dataset), current_time)\n",
    "extractor_model_save_callback = keras.callbacks.ModelCheckpoint(filepath=extractor_model_path, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = keras.Sequential([inception_model, keras.layers.Dense(num_classes(dataset), activation='softmax')])\n",
    "feature_extractor.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.fit(extractor_train, validation_data=extractor_val, callbacks=[extractor_tensorboard_callback, extractor_model_save_callback], epochs=20)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
